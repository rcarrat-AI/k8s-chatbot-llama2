apiVersion: v1
kind: ConfigMap
metadata:
  name: llama2-config
data:
  n_threads: "2"
  n_batch: "512"
  n_gpu_layers: "40"
  n_ctx: "4096"
  title: "ðŸ¦œðŸ”— Chatbot LLama2 on Kubernetes"
  description: "Chatbot using LLama2 GGML model running on top of Kubernetes"
  port: "8080"
  model_name_or_path: "TheBloke/Llama-2-13B-chat-GGML"
  model_basename: "llama-2-13b-chat.ggmlv3.q5_1.bin"
